{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcCzU+tmAWx2enfcNzh3su",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilliraj1987/awesome-public-datasets/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuqT_gE0FrLy",
        "outputId": "e2c63252-0664-44e2-bb94-0b158a590099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GV_DeepLearning'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 953\u001b[K\n",
            "Receiving objects: 100% (956/956), 18.10 MiB | 27.05 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/vadivukar/GV_DeepLearning/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "TIKowIVdL9jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F-RAV5-WM0W8",
        "outputId": "ecc040fc-8b3b-49de-c1b3-e8dc11359ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/GV_DeepLearning/Dataset/TrainingSet', target_size = (64,64), batch_size = 32, class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttDVKqfFM4im",
        "outputId": "ac216f01-928d-41da-bd61-4a1476839f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 692 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/GV_DeepLearning/Dataset/TestSet', target_size = (64,64), batch_size = 32, class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twuJtpg6N7Hc",
        "outputId": "fea01f9d-4e2a-4206-a0d2-d0e5006eedf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "C5mskALgOVXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "YfsJ5zOpOinm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "C43aqxx_O_Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "9L4SaHW-PWeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "axBArFd6Pfui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SN2V62FMRLIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0w8ywYKRmfG",
        "outputId": "a43d7b71-6cbb-409f-e49c-6c3160001db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 8s 294ms/step - loss: 0.6970 - accuracy: 0.5434 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 7s 312ms/step - loss: 0.6537 - accuracy: 0.5824 - val_loss: 0.7915 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.6211 - accuracy: 0.6402 - val_loss: 0.6925 - val_accuracy: 0.5800\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.5830 - accuracy: 0.6806 - val_loss: 0.7331 - val_accuracy: 0.5500\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.5768 - accuracy: 0.6893 - val_loss: 0.6403 - val_accuracy: 0.6100\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 6s 277ms/step - loss: 0.5461 - accuracy: 0.7370 - val_loss: 0.6165 - val_accuracy: 0.6600\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 6s 264ms/step - loss: 0.5243 - accuracy: 0.7355 - val_loss: 0.6338 - val_accuracy: 0.6300\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.5145 - accuracy: 0.7514 - val_loss: 0.6154 - val_accuracy: 0.6400\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.5001 - accuracy: 0.7500 - val_loss: 0.6627 - val_accuracy: 0.6600\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 6s 269ms/step - loss: 0.4906 - accuracy: 0.7572 - val_loss: 0.7815 - val_accuracy: 0.6200\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 6s 283ms/step - loss: 0.4792 - accuracy: 0.7486 - val_loss: 0.6601 - val_accuracy: 0.6200\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 6s 268ms/step - loss: 0.4764 - accuracy: 0.7861 - val_loss: 0.8597 - val_accuracy: 0.5900\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 6s 272ms/step - loss: 0.4533 - accuracy: 0.7876 - val_loss: 0.6359 - val_accuracy: 0.6800\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 6s 275ms/step - loss: 0.4558 - accuracy: 0.7645 - val_loss: 0.6692 - val_accuracy: 0.6600\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 6s 274ms/step - loss: 0.4939 - accuracy: 0.7529 - val_loss: 0.6364 - val_accuracy: 0.7000\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 6s 278ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.6721 - val_accuracy: 0.6500\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 6s 276ms/step - loss: 0.4069 - accuracy: 0.8107 - val_loss: 0.6606 - val_accuracy: 0.6900\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.3846 - accuracy: 0.8121 - val_loss: 0.7011 - val_accuracy: 0.6700\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 7s 329ms/step - loss: 0.4007 - accuracy: 0.8194 - val_loss: 0.6867 - val_accuracy: 0.6900\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 9s 410ms/step - loss: 0.3862 - accuracy: 0.8251 - val_loss: 0.5783 - val_accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0c7cb7650>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/GV_DeepLearning/Dataset/SingleImage/cat_or_dog_2.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "KmTv-w6VRs6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mliXViOSrxO",
        "outputId": "c1c21b06-6572-4986-e5b2-c64f222a6d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-e3N4WngS8Iv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}